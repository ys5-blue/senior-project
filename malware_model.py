import torch
from torch import nn, optim, functional as F
from pytorch_lightning import LightningModule

class MalwareModel(LightningModule):
    def __init__(self):
        super().__init__()
        self.embedding = nn.Embedding(256, 16)
        self.layers = nn.Sequential(
            nn.Conv1d(16, 32, 16),
            nn.ReLU(),
            nn.MaxPool1d(4),
            nn.Conv1d(32, 64, 16),
            nn.ReLU(),
            nn.MaxPool1d(4),
            nn.Conv1d(64, 128, 16),
            nn.ReLU(),
            nn.MaxPool1d(8),
            nn.Conv1d(128, 256, 8),
            nn.ReLU(),
            nn.MaxPool1d(8),
            nn.Conv1d(256, 512, 8),
            nn.ReLU(),
        )
        self.logits = nn.Linear(512, 9)
        self.loss_fn = nn.CrossEntropyLoss()

    def forward(self, x):
        x = self.embedding(x)
        x = torch.transpose(x, 1, -1)
        x = self.layers(x)
        x = torch.mean(x, dim=-1)
        return self.logits(x)

    def configure_optimizers(self):
        return optim.Adam(self.parameters())

    def training_step(self, batch, batch_idx):
        features, labels = batch
        predicted_logits = self.forward(features)
        loss = self.loss_fn(predicted_logits, labels)
        accuracy = (predicted_logits.argmax(dim=-1) == labels).float().mean()
        self.log('acc', accuracy, prog_bar=True)
        return loss
